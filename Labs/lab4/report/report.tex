\documentclass{ETHExercise}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{float}
\usepackage{subfig}
\usepackage{adjustbox}
\usepackage[margin=2cm]{geometry}
\usepackage{fancyhdr}
\usepackage{capt-of}
\usepackage{tabularx}
\usepackage{bm}
\usepackage{amsmath}
\usepackage{datetime}
\usepackage{listings}
\usepackage{subcaption}



\pagestyle{fancy}
\fancyhf{}
\fancyfoot[L]{263-5902-00L W23 / Lab report}
\fancyfoot[C]{\thepage}
\fancyfoot[R]{Computer Science\\ETH ZÃ¼rich}
\renewcommand{\footrulewidth}{0.05pt}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrule}{\hrule width\textwidth height\footrulewidth \vskip 2pt}
\newcommand{\timestamp}{\ddmmyyyydate\today \,\,- \currenttime h}

\usepackage{mdframed}
\usepackage{etoolbox}

\newtoggle{showA}
\toggletrue{showA}





\hypersetup{colorlinks,urlcolor=blue}
\lstset{
  backgroundcolor=\color{lightgray!20},
  basicstyle=\small\ttfamily,
  keywordstyle=\color{blue}\ttfamily,
  language=C,
  numbers=left,
  stepnumber=1,
  tabsize=4,
  showspaces=false,
  showstringspaces=false,
}
\title{Lab 2}
\author{Filippo Ficarra}
\begin{document}


\lectureheader{Prof. M. Pollefeyes}
{}
{\Large Computer Vision}{Fall 2023}
\begin{center}
    {\Huge Filippo Ficarra: Lab 4 - Object Recognition}\\
      \quad\newline
      fficarra@student.ethz.ch, 22--938--062.\\
      \quad\newline
      \timestamp
      \end{center}

\section{Introduction}
The first part of the lab focuses on image recognition in a more 
classical way,l using a method borrowed from NLP. The Bag of word method is a 
method for Image recognition it is adapted this way:
\begin{itemize}
  \item Divide the images in subimages 
  \item Create a codebook of explenative images
  \item Correlate images to the one in the codebook to classify them
\end{itemize}

The second method uses a Deep Learning architecture to extract information
and classify the images. This is done through the usage of a simplified
version of the VGG architecture.

\section{Bag of Words}
\subsection{Grid}
The image is divided into a grid. The grid is created with the 
following steps:
\begin{itemize}
  \item leave a border on all the edges. In this case border = 8
  \item compute the width and height of the grid 
  \item take all the points that start from border to the image width border and analogously for the height
  \item create an array of points from the step before
\end{itemize}

\subsection{Histogram of Oriented gradients}
In order to extract the feature we use the HOG algorithm. The variant
used in this exercise doesn't use the magnitudes of the gradient but just
their orientation.

For each grid point specified in vPoints, the algorithm computes a HOG descriptor using the following steps:
\begin{itemize}
  \item It iterates over a 4x4 set of cells around the current grid point.
  \item For each cell, it calculates the gradient orientation and computes a hog.
  \item The histogram counts how many gradient orientations fall into each of the predefined bins (from -180 to 180 degrees, since arctan gives values in this range).


\end{itemize}
\subsection{Codebook}
The book is generated gathering all the descriptors for all the sub images 
taken from the grid of all images and clusterizing them using the K-means cluster
algorithm. The code was already implemented and the following code
was added:
\begin{lstlisting}[language=Python, caption=Codebook Generation]
  grid = grid_points(img, nPointsX, nPointsY, border)
  descriptors = descriptors_hog(img, grid, cellWidth, cellHeight)
  vFeatures.append(descriptors)
\end{lstlisting}

We will further analyze the importance of the parameter k.
\subsection{Bag-of-Words histogram}
In the function create\_bow\_histograms() we compute for the descriptors of all the images 
the histogram that relates each feature to a the centroids. The function
relies on the function bow\_histogram() function that computes the histogram of the features of an images
with respect to the centroids.

\subsection{Nearest Neighbour}

The classification is done using the findnn function to find both the 
distances of the positive BoW and the negative BoW. The smallest distance
is the class we predict.

\subsection{Results}
The following results show the trend of the posistive and negative samples when the number
of centroids vary.

Insert the logging

\section{CNN-based Classifier}

\subsection{Training}
The model is a simplified version of the VGG architecture. The architecture given was
the following:

\begin{figure}[!h]
  \centering
  \includegraphics[width=0.6\textwidth, height=0.15\textheight]{images/VGG.png}
  \caption{VGG simplified architecture}
\end{figure}

The model was trained with the following parameters:
\begin{center}
  \begin{tabular}{|l|c|c|c|}
    \hline
    \textbf{Argument} & \textbf{Value} &  \textbf{Description} \\
    \hline
    batch\_size & 128 & Batch size \\
    log\_step & 100 & How many steps to log once \\
    val\_step & 100 &  Validation step \\
    num\_epoch & 50 & Maximum number of training epochs \\
    fc\_layer & 512 & Number of features in the first linear layer in VGG \\
    lr & 0.0001 &  Learning rate \\
    \hline
  \end{tabular}
\end{center}


As shown in the table above the model was trained for 50 epochs with batch size 128.
\\
Furthermore the training has been performed on Euler with 1 gpu RTX 4090. 
\\
Below we can find the graphs for the train losses in which we can see that the 
loss progressively drops from an initial value of 2 to a value around 1.3, while the validation accuracies
pass from around 45\% to a final value of 81.92\%

\begin{figure}[h]
  \centering
  \includegraphics[width=1\textwidth, height=0.22\textheight]{images/train_losses.png}
  \caption{Train Losses}
\end{figure}
\begin{figure}[h]
  \centering
  \includegraphics[width=1\textwidth, height=0.22\textheight]{images/val_accuracies.png}
  \caption{Validation Accuracies}
\end{figure}

\subsection{Testing}
The model after training with 50 epochs achieved a test accuracy of 80.86 on the CIFAR10 dataset.
The test script was run locally on cpu for convenience and gave the following output:
\begin{figure}[!h]
  \centering
  \includegraphics[width=0.3\textwidth]{images/test_output.png}
\end{figure}

\end{document}
