\documentclass{ETHExercise}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{float}
\usepackage{subfig}
\usepackage{adjustbox}
\usepackage[margin=2cm]{geometry}
\usepackage{fancyhdr}
\usepackage{capt-of}
\usepackage{tabularx}
\usepackage{bm}
\usepackage{amsmath}
\usepackage{datetime}
\usepackage{listings}
\usepackage{subcaption}



\pagestyle{fancy}
\fancyhf{}
\fancyfoot[L]{263-5902-00L W23 / Lab report}
\fancyfoot[C]{\thepage}
\fancyfoot[R]{Computer Science\\ETH ZÃ¼rich}
\renewcommand{\footrulewidth}{0.05pt}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrule}{\hrule width\textwidth height\footrulewidth \vskip 2pt}
\newcommand{\timestamp}{\ddmmyyyydate\today \,\,- \currenttime h}

\usepackage{mdframed}
\usepackage{etoolbox}

\newtoggle{showA}
\toggletrue{showA}





\hypersetup{colorlinks,urlcolor=blue}
\lstset{
  backgroundcolor=\color{lightgray!20},
  basicstyle=\small\ttfamily,
  keywordstyle=\color{blue}\ttfamily,
  language=C,
  numbers=left,
  stepnumber=1,
  tabsize=4,
  showspaces=false,
  showstringspaces=false,
}
\title{Lab 2}
\author{Filippo Ficarra}
\begin{document}


\lectureheader{Prof. M. Pollefeyes}
{}
{\Large Computer Vision}{Fall 2023}
\begin{center}
    {\Huge Filippo Ficarra: Lab 4 - Object Recognition}\\
      \quad\newline
      fficarra@student.ethz.ch, 22--938--062.\\
      \quad\newline
      \timestamp
      \end{center}

\section{Introduction}

\section{Bag of Words}
\subsection{Grid}
The image is divided into a grid. The grid is created with the 
following steps:
\begin{itemize}
  \item leave a border on all the edges. In this case border = 8
  \item compute the width and height of the grid 
  \item take all the points that start from border to the image width border and analogously for the height
  \item create an array of points from the step before
\end{itemize}

\subsection{Histogram of Oriented gradients}
In order to extract the feature we use the HOG algorithm. The variant
used in this exercise doesn't use the magnitudes of the gradient but just
their orientation.

TO COMPLETE
\subsection{Codebook}
The book is generated gathering all the descriptors for all the sub images 
taken from the grid of all images and clusterizing them using the K-means cluster
algorithm. The code was already implemented and the following code
was added:
\begin{lstlisting}[language=Python, caption=Codebook Generation]
  grid = grid_points(img, nPointsX, nPointsY, border)
  descriptors = descriptors_hog(img, grid, cellWidth, cellHeight)
  vFeatures.append(descriptors)
\end{lstlisting}

\subsection{Bag-of-Words histogram}
In the function create\_bow\_histograms() we compute for the descriptors of all the images 
the histogram that relates each feature to a the centroids. The function
relies on the function bow\_histogram() function that computes the histogram of the features of an images
with respect to the centroids.

\subsection{Nearest Neighbour}

The classification is done using the findnn function to find both the 
distances of the positive BoW and the negative BoW. The smallest distance
is the class we predict.

\section{CNN-based Classifier}

\subsection{Training}
The model is a simplified version of the VGG architecture. The architecture given was
the following:

\begin{figure}[!h]
  \centering
  \includegraphics[width=0.6\textwidth, height=0.15\textheight]{images/VGG.png}
  \caption{VGG simplified architecture}
\end{figure}

The model was trained with the following parameters:
\begin{center}
  \begin{tabular}{|l|c|c|c|}
    \hline
    \textbf{Argument} & \textbf{Value} &  \textbf{Description} \\
    \hline
    batch\_size & 128 & Batch size \\
    log\_step & 100 & How many steps to log once \\
    val\_step & 100 &  Validation step \\
    num\_epoch & 50 & Maximum number of training epochs \\
    fc\_layer & 512 & Number of features in the first linear layer in VGG \\
    lr & 0.0001 &  Learning rate \\
    \hline
  \end{tabular}
\end{center}


As shown in the table above the model was trained for 50 epochs with batch size 128.
\\
Furthermore the training has been performed on Euler with 1 gpu RTX 4090. 
\\
Below we can find the graphs for the train losses in which we can see that the 
loss progressively drops from an initial value of 2 to a value around 1.3, while the validation accuracies
pass from around 45\% to a final value of 81.92\%

\begin{figure}[h]
  \centering
  \includegraphics[width=1\textwidth, height=0.22\textheight]{images/train_losses.png}
  \caption{Train Losses}
\end{figure}
\begin{figure}[h]
  \centering
  \includegraphics[width=1\textwidth, height=0.22\textheight]{images/val_accuracies.png}
  \caption{Validation Accuracies}
\end{figure}

\newpage
\subsection{Testing}
The model after training with 50 epochs achieved a test accuracy of 80.86 on the CIFAR10 dataset.
The test script was run locally on cpu for convenience and gave the following output:
\begin{figure}[h]
  \centering
  \includegraphics[width=0.3\textwidth]{images/test_output.png}
\end{figure}

\end{document}
