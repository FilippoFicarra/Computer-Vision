\documentclass{ETHExercise}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{float}
\usepackage{subfig}
\usepackage{adjustbox}
\usepackage[margin=2cm]{geometry}
\usepackage{fancyhdr}
\usepackage{capt-of}
\usepackage{tabularx}
\usepackage{bm}
\usepackage{amsmath}
\usepackage{datetime}
\usepackage{listings}
\usepackage{subcaption}
\usepackage[ruled,vlined]{algorithm2e}




\pagestyle{fancy}
\fancyhf{}
\fancyfoot[L]{263-5902-00L W23 / Lab report}
\fancyfoot[C]{\thepage}
\fancyfoot[R]{Computer Science\\ETH ZÃ¼rich}
\renewcommand{\footrulewidth}{0.05pt}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrule}{\hrule width\textwidth height\footrulewidth \vskip 2pt}
\newcommand{\timestamp}{\ddmmyyyydate\today \,\,- \currenttime h}

\usepackage{mdframed}
\usepackage{etoolbox}

\newtoggle{showA}
\toggletrue{showA}





\hypersetup{colorlinks,urlcolor=blue}
\lstset{
  backgroundcolor=\color{lightgray!20},
  basicstyle=\small\ttfamily,
  keywordstyle=\color{blue}\ttfamily,
  language=C,
  numbers=left,
  stepnumber=1,
  tabsize=4,
  showspaces=false,
  showstringspaces=false,
}
\title{Lab 5}
\author{Filippo Ficarra}
\begin{document}


\lectureheader{Prof. M. Pollefeyes}
{}
{\Large Computer Vision}{Fall 2023}
\begin{center}
    {\Huge Filippo Ficarra: Lab 7 - Structure from Motion and Line Fitting}\\
      \quad\newline
      fficarra@student.ethz.ch, 22--938--062.\\
      \quad\newline
      \timestamp
      \end{center}



\section{Structure from Motion}
\subsection{Implementation}
The principal functions that had to be implemented were:
\begin{itemize}
  \item Essential matrix estimation
  \item Point triangulation
  \item Map extension
\end{itemize}

\subsubsection{Essential matrix estimation}

\begin{lstlisting}[language=Python, caption=homogeneous coordinate and normalizing]
  homogeneous_kps1 = np.array([MakeHomogeneous(kp) for kp in im1.kps[matches[:,0]]])
  homogeneous_kps2 = np.array([MakeHomogeneous(kp) for kp in im2.kps[matches[:,1]]])
  
  K_inv = np.linalg.inv(K)

  normalized_kps1 = (K_inv @ homogeneous_kps1.T).T
  normalized_kps2 = (K_inv @ homogeneous_kps2.T).T

\end{lstlisting}

In this code I went to homogeneous coordinates and then I normalized the points.

\begin{lstlisting}[language=Python, caption=homogeneous coordinate and normalizing]

constraint_matrix = np.zeros((matches.shape[0], 9))
for i in range(matches.shape[0]):
  # Add the constraints
  x1 = normalized_kps1[i]
  x2 = normalized_kps2[i]

  for j in range(x1.shape[0]):
    for k in range(x2.shape[0]):
      constraint_matrix[i, j * x2.shape[0] + k] = x2[j] * x1[k]
\end{lstlisting}

The previous code was used to find the constraint matrix from 
the formula $x_2^T E x_1 = 0$.

The we need to perform svd on the constraint matrix to find
the essential matrix imposing the first 2 singular values 
to be 1 and the third to be 0.

\subsubsection{Point triangulation}

\begin{lstlisting}[language=Python, caption=point triangulation]
  homogeneous_points3D = np.array([MakeHomogeneous(p) for p in points3D])
  points3D_cam1 = (P1 @ homogeneous_points3D.T).T
  indices = np.where(points3D_cam1[:,2] > 0)[0]
  
  
  # Filter points behind the first camera
  im1_corrs = im1_corrs[indices]
  im2_corrs = im2_corrs[indices]
  points3D = points3D[indices]
  
  
  homogeneous_points3D = np.array([MakeHomogeneous(p) for p in points3D])
  if len(homogeneous_points3D.shape) < 2: # since the last point is shaped as (0, ) instead of (0, 4)
    homogeneous_points3D = np.reshape(homogeneous_points3D, (0, 4))
  points3D_cam2 = (P2 @ homogeneous_points3D.T).T
  indices = np.where(points3D_cam2[:,2] > 0)[0]

  # Filter points behind the second camera
  im1_corrs = im1_corrs[indices]
  im2_corrs = im2_corrs[indices]
  points3D = points3D[indices]

\end{lstlisting}

In this code we first compute the 3D points from the cam 1 and 2. We then filter
the points for the one that have Z-coordinate $<$ 0, so they are behind 
the camera.

\subsubsection{Map extension}

\begin{lstlisting}[language=Python, caption=Trinagulate images]

  corrs = {}
  
  offset = 0
  for registered_image in registered_images:
    
    m = GetPairMatches(image_name, registered_image, matches)
    
    points3D_, im1_corrs, im2_corrs = TriangulatePoints(K, image, images[registered_image], m)
    points3D = np.append(points3D, points3D_, 0)
    
    corrs[image_name] = (im1_corrs, [i + offset for i in range(points3D_.shape[0])])
    
    offset += points3D_.shape[0]
\end{lstlisting}

\subsection{Results}
The following imges show the result for the algorithm using all the images.
Since the last 2 images contain some points far in the background, the cloud of 
points shows also them.

\begin{figure}[!h]
  \minipage{0.5\textwidth}
    \includegraphics[width=1.1\linewidth]{images/Figure_10.png}
  \endminipage
  \minipage{0.5\textwidth}
    \includegraphics[width=1.1\linewidth]{images/Figure_11.png}
  \endminipage
  \caption{Images 8 and 9 with the points in the background.}
\end{figure}


\begin{figure}[!h]
  \minipage{0.5\textwidth}
    \includegraphics[width=1.2\linewidth]{images/Figure_1_1.png}
  \endminipage
  \minipage{0.5\textwidth}
    \includegraphics[width=1.2\linewidth]{images/Figure_1_2.png}
  \endminipage\\
  \minipage{0.5\textwidth}
    \includegraphics[width=1.2\linewidth]{images/Figure_1_3.png}
  \endminipage
  \caption{Results for all the images. From top left to bottom right:
  top-right frontal , top-frontal, back views.}
\end{figure}

\newpage
If we remove the last two images we can clearly see the reconstruction 
of the fountain as shown below. The construction is much more visible,
there are less points to be considered when computing and plotting.


\begin{figure}[!h]
  \minipage{0.5\textwidth}
    \includegraphics[width=\linewidth]{images/Figure_1.png}
  \endminipage
  \minipage{0.5\textwidth}
    \includegraphics[width=\linewidth]{images/Figure_2.png}
  \endminipage\\
  \minipage{0.5\textwidth}
    \includegraphics[width=\linewidth]{images/Figure_3.png}
  \endminipage
  \minipage{0.5\textwidth}
    \includegraphics[width=\linewidth]{images/Figure_4.png}
  \endminipage
  \caption{Results for images 0 to 7. From top left to bottom right:
  frontal, top-frontal, top, back views.}
\end{figure}
 
\newpage
\section{Model Fitting}

\subsection{Implementation}

The main function of the algorithm is shown below. The algorithm
basically iterate all over the number of iterations, samples a random sample of
points and compute the least squares. The least squares coefficient are then 
passed to a function to compute the number of outliers and their indices.
\begin{lstlisting}[language=Python, caption=RANSAC]
  def ransac(x,y,iter,n_samples,thres_dist,num_subset):
    k_ransac = None
    b_ransac = None
    inlier_mask = None
    best_inliers = 0
  
    for _ in range(iter):
      indices = random.sample(range(n_samples), num_subset)
    
      k, b = least_square(x[indices], y[indices])
    
      num, mask = num_inlier(x, y, k, b, n_samples, thres_dist)
      
      if num > best_inliers:
        best_inliers = num
        k_ransac = k
        b_ransac = b
        inlier_mask = mask


    return k_ransac, b_ransac, inlier_mask
\end{lstlisting}

The inliers are computed with the following function:
\begin{lstlisting}[language=Python, caption=num\_inlier]
  def num_inlier(x,y,k,b,n_samples,thres_dist):
    num = 0
    mask = np.zeros(x.shape, dtype=bool)

    # distance point line
    line = k*x + b
    dist = np.abs(line-y) / np.sqrt(k**2 + 1)

    mask = dist < thres_dist
  
    num = len(dist[mask])

    return num, mask
\end{lstlisting}
A point is considered to be inlier if the its distance from the line is less then a threshold.


\subsection{Results}
In this section we are going to show the result for the RANSAC algorithm.
The value for the k and be for the 3 methods are the following:

\begin{itemize}
  \item $k_{gt} = 1,\ b_{gt} = 10$
  \item $k_{ls} = 0.615965657875546, \ b_{ls} = 8.961727141443642$
  \item $k_{RANSAC} = 0.9643894946568982,\ b_{RANSAC} = 9.982921294966832$
\end{itemize}

As shown above, the coefficient for the RANSAC are a very good estimation of the
ground truth line, while the least squares is far away from the real
line, due to the outliers present in the dataset.

These are the resulting lines that you can see in the figure below:
\begin{center}
  $y_{gt} = x + 10$\\
  $y_{ls} = 0.615965657875546 * x + 8.961727141443642 $\\
  $y_{RANSAC} = 0.9643894946568982 * x + 9.982921294966832$
\end{center}

\begin{figure}[!h]
  \includegraphics[width=\linewidth]{images/Model_fitting.png}
  \caption{Model fitting results.}
\end{figure}



\end{document}